{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7979385-9d86-4970-9b6d-feb639defb35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter will be restarted.\nRequirement already satisfied: transformers in /local_disk0/.ephemeral_nfs/envs/pythonEnv-824d2b7c-ac4a-47ca-a181-b31ed4937231/lib/python3.9/site-packages (4.51.3)\nRequirement already satisfied: pymupdf in /local_disk0/.ephemeral_nfs/envs/pythonEnv-824d2b7c-ac4a-47ca-a181-b31ed4937231/lib/python3.9/site-packages (1.25.5)\nRequirement already satisfied: scikit-learn in /databricks/python3/lib/python3.9/site-packages (1.0.2)\nCollecting hf_xet\n  Downloading hf_xet-1.0.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (54.0 MB)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-824d2b7c-ac4a-47ca-a181-b31ed4937231/lib/python3.9/site-packages (from transformers) (0.21.1)\nRequirement already satisfied: regex!=2019.12.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-824d2b7c-ac4a-47ca-a181-b31ed4937231/lib/python3.9/site-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /databricks/python3/lib/python3.9/site-packages (from transformers) (2.27.1)\nRequirement already satisfied: packaging>=20.0 in /databricks/python3/lib/python3.9/site-packages (from transformers) (21.3)\nRequirement already satisfied: numpy>=1.17 in /databricks/python3/lib/python3.9/site-packages (from transformers) (1.21.5)\nRequirement already satisfied: tqdm>=4.27 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-824d2b7c-ac4a-47ca-a181-b31ed4937231/lib/python3.9/site-packages (from transformers) (4.67.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-824d2b7c-ac4a-47ca-a181-b31ed4937231/lib/python3.9/site-packages (from transformers) (0.30.2)\nRequirement already satisfied: safetensors>=0.4.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-824d2b7c-ac4a-47ca-a181-b31ed4937231/lib/python3.9/site-packages (from transformers) (0.5.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.9.0)\nRequirement already satisfied: pyyaml>=5.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-824d2b7c-ac4a-47ca-a181-b31ed4937231/lib/python3.9/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: joblib>=0.11 in /databricks/python3/lib/python3.9/site-packages (from scikit-learn) (1.1.1)\nRequirement already satisfied: scipy>=1.1.0 in /databricks/python3/lib/python3.9/site-packages (from scikit-learn) (1.7.3)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.9/site-packages (from scikit-learn) (2.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-824d2b7c-ac4a-47ca-a181-b31ed4937231/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\nRequirement already satisfied: fsspec>=2023.5.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-824d2b7c-ac4a-47ca-a181-b31ed4937231/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /databricks/python3/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.4)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /databricks/python3/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.9/site-packages (from requests->transformers) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.9/site-packages (from requests->transformers) (1.26.9)\nInstalling collected packages: hf-xet\nSuccessfully installed hf-xet-1.0.5\nPython interpreter will be restarted.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers pymupdf scikit-learn hf_xet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a24accca-3e8b-466f-bd30-992e8fd95d1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter will be restarted.\nCollecting torch\n  Downloading torch-2.7.0-cp39-cp39-manylinux_2_28_x86_64.whl (865.2 MB)\nCollecting nvidia-cufft-cu12==11.3.0.4\n  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\nCollecting nvidia-nvjitlink-cu12==12.6.85\n  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\nCollecting nvidia-cuda-cupti-cu12==12.6.80\n  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\nCollecting nvidia-cuda-runtime-cu12==12.6.77\n  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\nCollecting networkx\n  Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\nCollecting nvidia-curand-cu12==10.3.7.77\n  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\nCollecting typing-extensions>=4.10.0\n  Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\nCollecting nvidia-nccl-cu12==2.26.2\n  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\nCollecting nvidia-nvtx-cu12==12.6.77\n  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\nCollecting nvidia-cusolver-cu12==11.7.1.2\n  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\nCollecting nvidia-cublas-cu12==12.6.4.1\n  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\nCollecting nvidia-cusparselt-cu12==0.6.3\n  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\nCollecting nvidia-cudnn-cu12==9.5.1.17\n  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch) (3.9.0)\nRequirement already satisfied: fsspec in /local_disk0/.ephemeral_nfs/envs/pythonEnv-824d2b7c-ac4a-47ca-a181-b31ed4937231/lib/python3.9/site-packages (from torch) (2025.3.2)\nCollecting nvidia-cufile-cu12==1.11.1.6\n  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\nCollecting nvidia-cuda-nvrtc-cu12==12.6.77\n  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\nCollecting triton==3.3.0\n  Downloading triton-3.3.0-cp39-cp39-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.4 MB)\nCollecting sympy>=1.13.3\n  Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\nCollecting nvidia-cusparse-cu12==12.5.4.2\n  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\nRequirement already satisfied: jinja2 in /databricks/python3/lib/python3.9/site-packages (from torch) (2.11.3)\nRequirement already satisfied: setuptools>=40.8.0 in /databricks/python3/lib/python3.9/site-packages (from triton==3.3.0->torch) (61.2.0)\nCollecting mpmath<1.4,>=1.1.0\n  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\nRequirement already satisfied: MarkupSafe>=0.23 in /databricks/python3/lib/python3.9/site-packages (from jinja2->torch) (2.0.1)\nInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-cusparse-cu12, nvidia-cublas-cu12, mpmath, typing-extensions, triton, sympy, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparselt-cu12, nvidia-cusolver-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, networkx, torch\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing-extensions 4.1.1\n    Not uninstalling typing-extensions at /databricks/python3/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-824d2b7c-ac4a-47ca-a181-b31ed4937231\n    Can't uninstall 'typing-extensions'. No files were found to uninstall.\nSuccessfully installed mpmath-1.3.0 networkx-3.2.1 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 sympy-1.14.0 torch-2.7.0 triton-3.3.0 typing-extensions-4.13.2\nPython interpreter will be restarted.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05d26ac7-d7a2-4b54-96cc-c2a089da8f11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d43a9bc-ab4c-4c33-b4e7-c6bbf6cf7752",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Simulated extracted text (pretend it came from a PDF)\n",
    "texts = [\n",
    "    \"Machine learning is a field of artificial intelligence that focuses on teaching computers to learn patterns.\",\n",
    "    \"Databricks is a cloud platform for big data and machine learning workflows.\",\n",
    "    \"Transformers are a type of deep learning model based on self-attention mechanisms.\",\n",
    "    \"Retrieval-augmented generation improves LLMs by letting them fetch facts from a knowledge base.\",\n",
    "    \"PyTorch is an open-source machine learning framework based on the Torch library.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "182bb251-73f7-4106-800c-82a8c8896fb7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def embed_texts(texts, model_name=\"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "    model.eval()\n",
    "\n",
    "    embeddings = []\n",
    "    for text in texts:\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            embedding = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "            embeddings.append(embedding)\n",
    "\n",
    "    return np.array(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c069d6a-6b38-4d21-a557-6024e45ebec5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "embeddings = embed_texts(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "314bd459-954e-4b44-a6c8-ac5597da0c9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def search_similar_texts(query, texts, embeddings, model_name=\"sentence-transformers/all-MiniLM-L6-v2\", top_k=3):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "    model.eval()\n",
    "\n",
    "    inputs = tokenizer(query, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        query_embedding = model(**inputs).last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "\n",
    "    query_embedding = np.expand_dims(query_embedding, axis=0)\n",
    "\n",
    "    similarities = cosine_similarity(query_embedding, embeddings)\n",
    "    top_indices = similarities[0].argsort()[-top_k:][::-1]\n",
    "\n",
    "    results = [texts[i] for i in top_indices]\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25593d9f-18f2-4a88-9b98-f16f448533c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Retrieved Passages:\n1. Databricks is a cloud platform for big data and machine learning workflows.\n--------------------------------------------------\n2. PyTorch is an open-source machine learning framework based on the Torch library.\n--------------------------------------------------\n3. Machine learning is a field of artificial intelligence that focuses on teaching computers to learn patterns.\n--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "query = \"What does Databricks do?\"\n",
    "top_results = search_similar_texts(query, texts, embeddings)\n",
    "\n",
    "print(\"Top Retrieved Passages:\")\n",
    "for i, passage in enumerate(top_results):\n",
    "    print(f\"{i+1}. {passage}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89be583a-d961-4c16-a04a-2d04ca7776b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eaa48f2f35e49e8b1ee0198ea31d74b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/451 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfbb1727ce104d059592fc5b58397ec9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/265M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bec296b416a14f698f066bcdd1e210e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6ad292974c14ec7897663af96833d1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cca4126e830e472cb01d00018434e03a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer:\na cloud platform for big data and machine learning workflows\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load a small QA model\n",
    "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\")\n",
    "\n",
    "context = \" \".join(top_results)\n",
    "\n",
    "result = qa_pipeline(question=query, context=context)\n",
    "print(\"Generated Answer:\")\n",
    "print(result['answer'])\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "RAG_pipeline",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}